{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Credit Risk Model Data Analysis Project** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Gallant Captain\n",
    "# Date: August 08, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 1:**\n",
    "* Our goal is to obtain a clean & preprocessed dataset\n",
    "* We'll note down the changes we're making to the original dataset\n",
    "* This information will be invaluable to the data scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 2:**\n",
    "1. Every categorical variable must be quantified.\n",
    "2. We need to change any text columns into numbers (Based on info).\n",
    "3. For others, we only care if they provide +ve or -ve connotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 3: Measuring Creditworthiness**\n",
    "* We need to be extremely risk-averse & distrustful.\n",
    "* Missing information suggests foul play.\n",
    "* If information isn't available, assume the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress= True, linewidth= 100, precision= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        nan         nan         nan ...         nan         nan         nan]\n",
      " [48010226.           nan    35000.   ...         nan         nan     9452.96]\n",
      " [57693261.           nan    30000.   ...         nan         nan     4679.7 ]\n",
      " ...\n",
      " [50415990.           nan    10000.   ...         nan         nan     2185.64]\n",
      " [46154151.           nan         nan ...         nan         nan     3199.4 ]\n",
      " [66055249.           nan    10000.   ...         nan         nan      301.9 ]]\n"
     ]
    }
   ],
   "source": [
    "#Import the Loan Data file, delimiter ';', encoding 'windows-1251'.\n",
    "file_location_1=\"loan-data.csv\"\n",
    "raw_data_np= np.genfromtxt(file_location_1, delimiter= \";\", encoding= \"windows-1251\")\n",
    "print(raw_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48010226.           nan    35000.   ...         nan         nan     9452.96]\n",
      " [57693261.           nan    30000.   ...         nan         nan     4679.7 ]\n",
      " [59432726.           nan    15000.   ...         nan         nan     1969.83]\n",
      " ...\n",
      " [50415990.           nan    10000.   ...         nan         nan     2185.64]\n",
      " [46154151.           nan         nan ...         nan         nan     3199.4 ]\n",
      " [66055249.           nan    10000.   ...         nan         nan      301.9 ]]\n"
     ]
    }
   ],
   "source": [
    "#Best practices code, use skipheader & autostrip \n",
    "raw_data_np= np.genfromtxt(file_location_1, delimiter= \";\", encoding= \"windows-1251\",\n",
    "                           skip_header= 1, autostrip= True)\n",
    "print(raw_data_np) #Now data looks much cleaner & clearer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checking for Incomplete Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for NAN values by calling np.isnan & use .sum() to check how many NAN values.\n",
    "np.isnan(raw_data_np).sum() #88005 NAN values as NAN is True (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avira\\AppData\\Local\\Temp\\ipykernel_9564\\3925349410.py:3: RuntimeWarning: Mean of empty slice\n",
      "  temporary_mean= np.nanmean(raw_data_np, axis= 0) #Hold the means for every column\n"
     ]
    }
   ],
   "source": [
    "#Create 2 temporary variables to handle the missing data\n",
    "temporary_fill= np.nanmax(raw_data_np) + 1 #A filler for all the missing entries of the dataset\n",
    "temporary_mean= np.nanmean(raw_data_np, axis= 0) #Hold the means for every column\n",
    "#Get the max value & mean value of the dataset\n",
    "#RuntimeWarning: Mean of empty slice (temporary_mean) - This means that there is atleast 1 empty column with NAN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "            440.92,         nan,         nan,         nan,         nan,         nan,     3143.85])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify the NAN warnings of the variable. 8 columns have NAN values.\n",
    "temporary_mean #Here, 'NAN mean' values means the columns only store strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avira\\AppData\\Local\\Temp\\ipykernel_9564\\3027522355.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  temporary_stats= np.array([np.nanmin(raw_data_np, axis= 0),\n",
      "C:\\Users\\avira\\AppData\\Local\\Temp\\ipykernel_9564\\3027522355.py:4: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(raw_data_np, axis= 0)])\n"
     ]
    }
   ],
   "source": [
    "#Fill out the missing variables of the missing columns\n",
    "temporary_stats= np.array([np.nanmin(raw_data_np, axis= 0),\n",
    "                                     temporary_mean,\n",
    "                                     np.nanmax(raw_data_np, axis= 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now print the filled out values\n",
    "temporary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting the Dataset**\n",
    "\n",
    "To split the data between which contains numerical and categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Splitting the Columns***\n",
    "By splitting we can then use usecols = ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If value 1 = 0. Column contains only text -> mean= NAN. np.isnan returns True for that column.\n",
    "columns_strings= np.argwhere(np.isnan(temporary_mean)).squeeze() \n",
    "columns_strings #Since True != 0, np.argwhere() returns the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Which columns contain numeric values. Columns that don't contain NAN values != NAN. np.isnan returns False for that column.\n",
    "columns_numeric= np.argwhere(np.isnan(temporary_mean) == False).squeeze() #,squeeze to return 1-D array\n",
    "columns_numeric #Since, False == 0, np.argwhere() returns the index of numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Re-Importing the Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['May-15' 'Current' '36 months' ... 'Verified'\n",
      "  'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226' 'CA']\n",
      " ['' 'Current' '36 months' ... 'Source Verified'\n",
      "  'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261' 'NY']\n",
      " ['Sep-15' 'Current' '36 months' ... 'Verified'\n",
      "  'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726' 'PA']\n",
      " ...\n",
      " ['Jun-15' 'Current' '36 months' ... 'Source Verified'\n",
      "  'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990' 'CA']\n",
      " ['Apr-15' 'Current' '36 months' ... 'Source Verified'\n",
      "  'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151' 'OH']\n",
      " ['Dec-15' 'Current' '36 months' ... ''\n",
      "  'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249' 'IL']]\n"
     ]
    }
   ],
   "source": [
    "#Split to String Dataset\n",
    "#Reimport dataset for string values and use skipheader & autostrip: Strips whitespace characters leading/trailing \n",
    "loan_data_strings= np.genfromtxt(file_location_1, delimiter= \";\", encoding= \"windows-1251\",\n",
    "                                 skip_header= 1, autostrip= True, dtype= np.str_,\n",
    "                                 usecols= columns_strings)\n",
    "print(loan_data_strings) #Now data is split for text values & looks much cleaner & clearer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48010226.      35000.      35000.         13.33     1184.86     9452.96]\n",
      " [57693261.      30000.      30000.   68616520.        938.57     4679.7 ]\n",
      " [59432726.      15000.      15000.   68616520.        494.86     1969.83]\n",
      " ...\n",
      " [50415990.      10000.      10000.   68616520.   68616520.       2185.64]\n",
      " [46154151.   68616520.      10000.         16.55      354.3      3199.4 ]\n",
      " [66055249.      10000.      10000.   68616520.        309.97      301.9 ]]\n"
     ]
    }
   ],
   "source": [
    "#Split to numeric dataset\n",
    "#Reimport dataset for numerical values and use skipheader & autostrip: Strips whitespace characters leading/trailing \n",
    "loan_data_numeric= np.genfromtxt(file_location_1, delimiter= \";\", encoding= \"windows-1251\",\n",
    "                                 skip_header= 1, autostrip= True, usecols= columns_numeric,\n",
    "                                 filling_values= temporary_fill)\n",
    "print(loan_data_numeric) #Now data is split for numerical values & looks much cleaner & clearer\n",
    "#We use filling values here as numerical NAN values will be handled differently than the text ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tips:**\n",
    "* We have successfully split the data into two types: Numerical and String type datasets for better analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***The Names of the Columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use a header variabl to keep track of the datasets\n",
    "header_full = np.genfromtxt(file_location_1, delimiter = \";\", encoding = \"windows-1251\", \n",
    "                            skip_footer= raw_data_np.shape[0], autostrip = True, dtype = np.str_)\n",
    "header_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2 new headers which are split based on string & numeric. These will be used later for the smaller datasets we're using.\n",
    "header_strings, header_numeric= header_full[columns_strings], header_full[columns_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['issue_d' 'loan_status' 'term' 'grade' 'sub_grade' 'verification_status' 'url' 'addr_state']\n"
     ]
    }
   ],
   "source": [
    "#Check the header string dataset\n",
    "print(header_strings) #The names of columns containing strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'loan_amnt' 'funded_amnt' 'int_rate' 'installment' 'total_pymnt']\n"
     ]
    }
   ],
   "source": [
    "#Check the header numeric dataset\n",
    "print(header_numeric) #The names of columns containing numerics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checkpoints**\n",
    "* Places throughout our code where we store a copy of our dataset (or parts of it)\n",
    "* We want to avoid losing a lot of progress (if data is accidentally overwritten)\n",
    "* An extremely reliable practice when we need to clean or preprocess many parts of a dataset.\n",
    "* A failsafe we can rely on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a checkpoint function to save data before we progress further\n",
    "def checkpoint(file_name, checkpoint_header, checkpoint_data):\n",
    "    np.savez(file_name, header= checkpoint_header, data= checkpoint_data)\n",
    "    checkpoint_variable= np.load(file_name + \".npz\") #Ensure, to add '.npz'\n",
    "    return(checkpoint_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the checkpoint function by storing the values\n",
    "checkpoint_test= checkpoint(\"checkpoint-test\", header_strings, loan_data_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now call the test checkpoint function\n",
    "checkpoint_test[\"header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now call the test checkpoint function\n",
    "checkpoint_test[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now test the checkpoint function has the same data as the original\n",
    "np.array_equal(checkpoint_test['data'], loan_data_strings) #Yes! Verified!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Manipulating Text Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Manipulating String Columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output the strings column header\n",
    "header_strings #These columns contain text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change name of header 1 for clarity\n",
    "header_strings[0]= \"issue_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check base dataset\n",
    "loan_data_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Issue Date***\n",
    "* Represent month values as integers\n",
    "* As integer values use less memory (storage) vis-a'-vis strings\n",
    "* Using numbers, we also get a more easy to follow order of months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['May-15', '', 'Sep-15', ..., 'Jun-15', 'Apr-15', 'Dec-15'], dtype='<U69')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only display the first column of the dataset\n",
    "loan_data_strings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15',\n",
       "       'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only display the first column of the dataset with unique values\n",
    "np.unique(loan_data_strings[:,0]) #Empty space means missing data. The data is arranged alphabetically and not chronologically as Python doesn't recognize them as time stamps as of yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip data part to get the string data only, ie, strip excess data\n",
    "loan_data_strings[:,0]= np.chararray.strip(loan_data_strings[:,0], \"-15\") #Strip the '-15' part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call unique function again to check if it was successful\n",
    "np.unique(loan_data_strings[:,0]) #Yes! It was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the months in a new array with months proper order. Begin with empty space.\n",
    "months= np.array([\"\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "                  \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a loop to traverse the isue date column and assign a numerical equivalent for the months\n",
    "for i in range(13):\n",
    "    loan_data_strings[:,0]= np.where(loan_data_strings[:,0] == months[i], #If month value matches then go to step 2.\n",
    "                                     i, #Assign it this value if it matches. The index from month[i] will match the string month in loan_data_strings dataset.\n",
    "                                     loan_data_strings[:,0]) #Dont change value if it doesn't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify if it is done\n",
    "np.unique(loan_data_strings[:,0]) #Yes, it has worked correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Loan Status***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the header data again for the column names\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Current', 'Current', 'Current', ..., 'Current', 'Current', 'Current'], dtype='<U69')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the entire loan_status column with indexing\n",
    "loan_data_strings[:,1] #loan_status is at column index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued',\n",
       "       'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the unique values of the loan_status column with indexing\n",
    "np.unique(loan_data_strings[:,1]) #This makes more sense now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the number of unique attributes in the column\n",
    "np.unique(loan_data_strings[:,1]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22080128"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the memory size of the file (optional step)\n",
    "loan_data_strings.__sizeof__() #The file occupies 22.08 Mb or 22080128 bytes of space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tips:**\n",
    "* We can use np.where() to assign a different number to each one.\n",
    "* We need to split all possible values into ether group (good v bad)\n",
    "* Regressions only care if the candidates are in good financial condition\n",
    "* For loans/credits always have to be risk-averse.\n",
    "* Good '1' - 'Current', 'Fully Paid', 'In Grace Period', 'Issued', 'Late (16-30 days): This can be due to getting salary at a fixed date & then paying.\n",
    "* Bad '0' - 'Charged Off', 'Default', ' '(No Date Provided), 'Late (31-120 days): This suggest there is a high possiblity candidate cannot keep up & default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an array with all the bad loan statuses\n",
    "status_bad= np.array(['', 'Charged Off', 'Default', 'Late (31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there is bad status in the loan dataset\n",
    "loan_data_strings[:,1]= np.where(np.isin(loan_data_strings[:,1], status_bad), 0, 1) \n",
    "#If it is there, assign it a 0 or else a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if substitution is successful\n",
    "np.unique(loan_data_strings[:,1]) #Yes! it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Term***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the string column header\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36 months', '36 months', '36 months', ..., '36 months', '36 months', '36 months'],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pick the second column, ie, Term column\n",
    "loan_data_strings[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now look for the unique values\n",
    "np.unique(loan_data_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '36', '36', ..., '36', '36', '36'], dtype='<U69')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Strip the excess data,i.e, 'months' string\n",
    "loan_data_strings[:,2]= np.chararray.strip(loan_data_strings[:,2], \" months\")\n",
    "loan_data_strings[:,2] #Call the function to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the term column to simplify it \n",
    "header_strings[2]= \"term_months\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substitute the values that match. When we have missing date, we assume the worst in Credit/Loan cases.\n",
    "loan_data_strings[:,2]= np.where(loan_data_strings[:,2] == \"\",\n",
    "                                 \"60\", #As 60 months is a very long period, we use that for the worst case scenario in missing values cases.\n",
    "                                 loan_data_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now look for the unique values. Normally for 2 value columns we use '0' & '1'. We should ensure that other values are optimal if 0 & 1 not used.\n",
    "np.unique(loan_data_strings[:,2]) #The missing value \"\" is gone & replaced with 60 months term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Grade & Sub-Grade Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status',\n",
       "       'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the header string function to check all columns\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the unique values from the grade column to improve our understanding of the data.\n",
    "np.unique(loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "       'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "       'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the unique values from the sub-grade column to improve our understanding of the data.\n",
    "np.unique(loan_data_strings[:,4]) #Both grade & sub-grade are interdependent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Filling Sub-Grade***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fillout emput spaces by traversing the sub-grade array\n",
    "for i in np.unique(loan_data_strings[:,3])[1:]:\n",
    "    loan_data_strings[:,4]= np.where((loan_data_strings[:,4] == \"\") & (loan_data_strings[:,3] == i),\n",
    "                                     i + '5', #The second condition is to check that the current iterator matches the current grade\n",
    "                                     loan_data_strings[:,4]) #To ensure that there is no mismatch between grade & sub-grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "       'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "       'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To verify the output. We still have '',ie, we still have missing data.\n",
    "np.unique(loan_data_strings[:,4]) #We still have rows where there are no grades/subgrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "        'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "        'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([  9, 285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267,\n",
       "        250, 255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To verify the output. We see that there are exactly 9 missing values from a row of 10,000 data values. \n",
    "np.unique(loan_data_strings[:,4], return_counts= True) #We can drop these 9 missing values as they are an insignificant part of the analysis. \n",
    "#However, as credit risk analysts we have to give every applicant a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fillout missing value with lowest category as missing values should be penalized.\n",
    "for i in np.unique(loan_data_strings[:,3])[1:]:\n",
    "    loan_data_strings[:,4]= np.where((loan_data_strings[:,4] == \"\"),\n",
    "                                     'H1', \n",
    "                                     loan_data_strings[:,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "       'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "       'G1', 'G2', 'G3', 'G4', 'G5', 'H1'], dtype='<U69')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the dataset again\n",
    "np.unique(loan_data_strings[:,4]) #We can see the new category H1. It was successful!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Removing Grade***\n",
    "* We remove Grade and only use sub-grade to reduce excess data and make analytics easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove the grade column altogether.\n",
    "loan_data_strings= np.delete(loan_data_strings, 3, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C3', 'A5', 'B5', ..., 'A5', 'D2', 'A4'], dtype='<U69')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now check if previous column 3 is removed.\n",
    "loan_data_strings[:,3] #Yes, grade is deleted & replaced at column 3 by sub-grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure that the header strings file is also updated with Grade column removal.\n",
    "header_strings= np.delete(header_strings, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub_grade'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the 4th column of the header string dataset\n",
    "header_strings[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Converting Sub-Grade***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "       'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "       'G1', 'G2', 'G3', 'G4', 'G5', 'H1'], dtype='<U69')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the unique sub-grade column values again for perusal\n",
    "np.unique(loan_data_strings[:,3]) #Many different values that we can convert into numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now construct a dictionary to convert the values into numeric. The + 1 at the end is necesary as range is close to open and it means the last number isn't included ie, only 35 values. So, +1 is needed for 36 values.\n",
    "keys= list(np.unique(loan_data_strings[:,3])) #Every key is a sub-grade as a string \n",
    "values= list(range(1, np.unique(loan_data_strings[:,3]).shape[0] + 1)) #Numeric values for each subgrade ranging from 1 - 35 + 1,ie, 1 - 36 values. (As range doesn't contain last value) \n",
    "dict_sub_grade= dict(zip(keys, values)) #Create a new dictionary with these values, with values acting as ranks of trustworthiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 1,\n",
       " 'A2': 2,\n",
       " 'A3': 3,\n",
       " 'A4': 4,\n",
       " 'A5': 5,\n",
       " 'B1': 6,\n",
       " 'B2': 7,\n",
       " 'B3': 8,\n",
       " 'B4': 9,\n",
       " 'B5': 10,\n",
       " 'C1': 11,\n",
       " 'C2': 12,\n",
       " 'C3': 13,\n",
       " 'C4': 14,\n",
       " 'C5': 15,\n",
       " 'D1': 16,\n",
       " 'D2': 17,\n",
       " 'D3': 18,\n",
       " 'D4': 19,\n",
       " 'D5': 20,\n",
       " 'E1': 21,\n",
       " 'E2': 22,\n",
       " 'E3': 23,\n",
       " 'E4': 24,\n",
       " 'E5': 25,\n",
       " 'F1': 26,\n",
       " 'F2': 27,\n",
       " 'F3': 28,\n",
       " 'F4': 29,\n",
       " 'F5': 30,\n",
       " 'G1': 31,\n",
       " 'G2': 32,\n",
       " 'G3': 33,\n",
       " 'G4': 34,\n",
       " 'G5': 35,\n",
       " 'H1': 36}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the results\n",
    "dict_sub_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass the numeric value for the grades\n",
    "for i in np.unique(loan_data_strings[:,3]): #For Loop goes through the unique array\n",
    "    loan_data_strings[:,3]= np.where(loan_data_strings[:,3] == i, #Condition to match this value\n",
    "                                     dict_sub_grade[i], #If matched, pass the associated value\n",
    "                                     loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the unique function to check the values\n",
    "np.unique(loan_data_strings[:,3]) #We see many numbers saved as strings. Verified!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Verification Status***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the header strings function to check the data\n",
    "header_strings #As previous grade column was deleted, column index 4 is now verification status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the unique values of the dataset\n",
    "np.unique(loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assume empty space \"\" is equivalent to not verified as per policy.\n",
    "loan_data_strings[:,4]= np.where((loan_data_strings[:,4] == '') | (loan_data_strings[:,4] == 'Not Verified'), #Check if conditions match\n",
    "                                 0, #Assign '0' if the condition is met\n",
    "                                 1) #Assign '1' otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not verify if the conversion was successful\n",
    "np.unique(loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***URL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the header-string function to check column integrity\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', ...,\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the url column from the dataset\n",
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chararray(['48010226', '57693261', '59432726', ..., '50415990', '46154151', '66055249'],\n",
       "          dtype='<U69')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Strip the excess data & only keep the numeric part. As we are not losing any crucial data, it is safe to overwrite this column.\n",
    "np.chararray.strip(loan_data_strings[:,5], \"https://www.lendingclub.com/browse/loanDetail.action?loan_id=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['48010226', '57693261', '59432726', ..., '50415990', '46154151', '66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we are not losing any crucial data, it is safe to overwrite this column.\n",
    "loan_data_strings[:,5]= np.chararray.strip(loan_data_strings[:,5], \"https://www.lendingclub.com/browse/loanDetail.action?loan_id=\")\n",
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the header full function to check all the headers\n",
    "header_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the numeric loan_data for comparision\n",
    "loan_data_numeric[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['48010226', '57693261', '59432726', ..., '50415990', '46154151', '66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the string loan_data to compare with above\n",
    "loan_data_strings[:,5] #Both are same values but different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify both dataset values are the same\n",
    "np.array_equal(loan_data_numeric[:,0].astype(dtype=np.int32), \n",
    "               loan_data_strings[:,5].astype(dtype=np.int32)) #Yes, both values are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove url from header and from strings loan data to clean it.\n",
    "loan_data_strings= np.delete(loan_data_strings, 5, axis= 1)\n",
    "header_strings= np.delete(header_strings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the datasets to verify\n",
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the header strings dataset to verify\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to verify that we did not delete irretrievable information\n",
    "loan_data_numeric[:,0] #Data is still there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify that the correct column data is also intact\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***State Address***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check all the colmuns of header strings\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the column to a better one\n",
    "header_strings[5]= 'state_address'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the column data\n",
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN',\n",
       "       'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
       "       'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
       "       'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now get the unique values to make sense of the dataset values. Baseline benchmark: Iowa.\n",
    "np.unique(loan_data_strings[:,5]) #US States along with missing value ''. Iowa is the missing state as a baseline benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tips:\n",
    "* When doing research or analysis on a variable with many categories, it is normal to pick one as a benchmark and include dummy variables for the rest. \n",
    "* The one without the dummy variable will serve as the base case.\n",
    "* We can increase/decrease the rest based in their coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the unique value size of the column\n",
    "np.unique(loan_data_strings[:,5]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN',\n",
       "        'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
       "        'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
       "        'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69'),\n",
       " array([ 500,   26,  119,   74,  220, 1336,  201,  143,   27,   27,  690,  321,   44,  389,  152,\n",
       "          84,   84,  116,  210,  222,   10,  267,  156,  160,   61,   28,  261,   16,   25,   58,\n",
       "         341,   57,  130,  777,  312,   83,  108,  320,   40,  107,   24,  143,  758,   74,  242,\n",
       "          17,  216,  148,   49,   27], dtype=int64))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now get the unique values to make sense of the dataset values. \n",
    "np.unique(loan_data_strings[:,5], return_counts= True) #Values are sorted in alphabetical order instead of numerical (population) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CA', 'NY', 'TX', 'FL', '', 'IL', 'NJ', 'GA', 'PA', 'OH', 'MI', 'NC', 'VA', 'MD', 'AZ',\n",
       "        'WA', 'MA', 'CO', 'MO', 'MN', 'IN', 'WI', 'CT', 'TN', 'NV', 'AL', 'LA', 'OR', 'SC', 'KY',\n",
       "        'KS', 'OK', 'UT', 'AR', 'MS', 'NH', 'NM', 'WV', 'HI', 'RI', 'MT', 'DE', 'DC', 'WY', 'AK',\n",
       "        'NE', 'SD', 'VT', 'ND', 'ME'], dtype='<U69'),\n",
       " array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,\n",
       "         216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,\n",
       "          84,   83,   74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,\n",
       "          25,   24,   17,   16,   10], dtype=int64))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort the dataset according to number of applicants to make sense of the data.\n",
    "#Use tuple assignment to store new variables\n",
    "states_names, states_count= np.unique(loan_data_strings[:,5], return_counts= True)\n",
    "states_count_sorted= np.argsort(-states_count) #-ve sign to sort it via descending order\n",
    "states_names[states_count_sorted], states_count[states_count_sorted] #Display variables according to the sorted indices.\n",
    "#There are more counts of missing values than 45 other US states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tips:\n",
    "* We have very little data for too many states to examine each one individually.\n",
    "* The more categories a variable has, the fewer data will be available for each one.\n",
    "* If we assign a unique value to each state this will allow outliers to have a big influence on the coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take care of missing values in the dataset first.\n",
    "loan_data_strings[:,5]= np.where(loan_data_strings[:,5] == '',\n",
    "                                 0, #Pass values of 0 so that it won't be included in any region\n",
    "                                 loan_data_strings[:,5]) #If it matches then value isn't altered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the states to common values to ensure more value weightage/coefficients\n",
    "states_east= np.array(['PA','NY','NJ','CT','MA','VT','NH','ME','RI'])\n",
    "states_west= np.array(['WA','OR','CA','NV','ID','MT','WY','UT','CO','AZ','NM','HI','AK'])\n",
    "states_south= np.array(['TX','OK','AR','LA','MS','AL','TN','KY','FL','GA','SC','NC','VA','WV','MD','DE','DC'])\n",
    "states_midwest= np.array(['ND','SD','NE','KS','MN','IA','MO','WI','IL','IN','MI','OH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the variables into larger groups for easier categorization\n",
    "loan_data_strings[:,5]= np.where(np.isin(loan_data_strings[:,5], states_west), 1, loan_data_strings[:,5])\n",
    "loan_data_strings[:,5]= np.where(np.isin(loan_data_strings[:,5], states_south), 2, loan_data_strings[:,5])\n",
    "loan_data_strings[:,5]= np.where(np.isin(loan_data_strings[:,5], states_midwest), 3, loan_data_strings[:,5])\n",
    "loan_data_strings[:,5]= np.where(np.isin(loan_data_strings[:,5], states_east), 4, loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4'], dtype='<U69')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify if successful\n",
    "np.unique(loan_data_strings[:,5]) #Yes verified. Values saved from 0 - 4, for easier analytical work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Converting to Numbers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36', '13', '1', '1'],\n",
       "       ['0', '1', '36', '5', '1', '4'],\n",
       "       ['9', '1', '36', '10', '1', '4'],\n",
       "       ...,\n",
       "       ['6', '1', '36', '5', '1', '1'],\n",
       "       ['4', '1', '36', '17', '1', '3'],\n",
       "       ['12', '1', '36', '4', '0', '3']], dtype='<U69')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the String dataset \n",
    "loan_data_strings #We can see it is full of numbers saved as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change data type from text to numeric for the dataset and store it\n",
    "loan_data_strings= loan_data_strings.astype(np.int32)\n",
    "loan_data_strings #Yes, successfully converted to integer/numerical datatype. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Checkpoint 1: Strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the checkpoint function from before\\ndef checkpoint(file_name, checkpoint_header, checkpoint_data):\\n    np.savez(file_name, header= checkpoint_header, data= checkpoint_data)\\n    checkpoint_variable= np.load(file_name + \".npz\") #Ensure, to add \\'.npz\\'\\n    return(checkpoint_variable)'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is the checkpoint function from before\n",
    "def checkpoint(file_name, checkpoint_header, checkpoint_data):\n",
    "    np.savez(file_name, header= checkpoint_header, data= checkpoint_data)\n",
    "    checkpoint_variable= np.load(file_name + \".npz\") #Ensure, to add '.npz'\n",
    "    return(checkpoint_variable)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new checkpoint for the String data so far & also save it in a new varaiable\n",
    "checkpoint1=\"Checkpoint-Strings\" #Output in same folder\n",
    "checkpoint_strings= checkpoint(checkpoint1, header_strings, loan_data_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the checkpoint variable with header argument\n",
    "checkpoint_strings[\"header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the checkpoint variable with data argument\n",
    "checkpoint_strings[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To be absolutely certain the 2 datasets are a match\n",
    "np.array_equal(checkpoint_strings['data'], loan_data_strings) #Only use the data argument as check_point strings also contains the header data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Manipulating Numeric Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the Numeric loan data to gain insights\n",
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values in the dataset and how many there are. \n",
    "np.isnan(loan_data_numeric).sum() #No missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Substitute Filler Values***\n",
    "* There aren't any missing values because we used filler values instead.\n",
    "* Therefore, we must substitute those filler values with the worst possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the header data to see all the columns it contains\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***ID***\n",
    "* To check whether any of the elements of the column equal the temporary_fill values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68616520.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reminder of the temporary fill value\n",
    "temporary_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the 1st column\n",
    "np.isin(loan_data_numeric[:,0], temporary_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now use the sum method to get the actual results\n",
    "np.isin(loan_data_numeric[:,0], temporary_fill).sum() #Column 1 doesn't contain filler values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the header columns again to identify the minimum value\n",
    "header_numeric #Only funded-amt could have the minimum amount considered the worst.\n",
    "#Thus we will switch the minimum value of funded_amt & the maximum value of all the other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Temporary Stats***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We had stored the min, mean & max in the temporary stats variable. Display to check content.\n",
    "temporary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Use indexing & plugin columns to ignore the NAN (string) values \\ntemporary_stats[:, header_numeric] #IndexError: arrays used as indices must be of integer (or boolean) type'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Use indexing & plugin columns to ignore the NAN (string) values \n",
    "temporary_stats[:, header_numeric] #IndexError: arrays used as indices must be of integer (or boolean) type\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     1000.  ,     1000.  ,        6.  ,       31.42,        0.  ],\n",
       "       [54015809.19,    15273.46,    15311.04,       16.62,      440.92,     3143.85],\n",
       "       [68616519.  ,    35000.  ,    35000.  ,       28.99,     1372.97,    41913.62]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use indexing & plugin columns to ignore the NAN (string) values \n",
    "temporary_stats[:, columns_numeric] #Temporary Min, Mean & Max respectively by rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Funded Amount***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000., 30000., 15000., ..., 10000., 10000., 10000.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the 3rd column for insights\n",
    "loan_data_numeric[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000., 30000., 15000., ..., 10000., 10000., 10000.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Funded amount should be substituted with minimum amount as that would make the most sense in context of credit/loan applications\n",
    "#Why? - Because we cannot expect max funded amount if the values are missing\n",
    "#Always be risk averse in credit/loan applications\n",
    "loan_data_numeric[:,2]= np.where(loan_data_numeric[:,2] == temporary_fill,\n",
    "                                 temporary_stats[0, columns_numeric[2]],\n",
    "                                 loan_data_numeric[:,2])\n",
    "loan_data_numeric[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the 4th individual element of the temporary stats variable\n",
    "temporary_stats[0,3] #This is because we generated temporary stats even before converting the loan-status string data to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the 4th numeric column from temporary stats\n",
    "temporary_stats[0, columns_numeric[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Loaned Amount, Interest Rate, Total Payment, Installation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the numeric header again to check columns \n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now iterate the column data of all columns except column 2 with the max value \n",
    "for i in [1,3,4,5]:\n",
    "    loan_data_numeric[:,i]= np.where(loan_data_numeric[:,i] == temporary_fill,\n",
    "                                     temporary_stats[2, columns_numeric[i]], # Row 2 in temporary_stats contains the max value of the columns\n",
    "                                     loan_data_numeric[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  ,       28.99,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  ,       28.99,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  ,       28.99,     1372.97,     2185.64],\n",
       "       [46154151.  ,    35000.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  ,       28.99,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the altered dataset with the filler values changed to max values in columns 1,3,4,5 & min values in column 2.\n",
    "loan_data_numeric #The filler values are now substituted with more fitting alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Currency Change***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***The Exchange Rate***\n",
    "* To ensure that the currency data can be easily converted to another for analytics at the \"time of the credit/loan application\".\n",
    "* We will need to convert the default currency from USD to EUR (based on office location & Data Analytics requirements for this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan,  nan,  nan],\n",
       "       [1.21, 1.21, 1.11, 1.13, 0.  ],\n",
       "       [1.13, 1.15, 1.12, 1.12, 0.  ],\n",
       "       [1.12, 1.12, 1.05, 1.08, 0.  ],\n",
       "       [1.07, 1.12, 1.05, 1.11, 0.  ],\n",
       "       [1.12, 1.15, 1.08, 1.1 , 0.  ],\n",
       "       [1.1 , 1.14, 1.09, 1.12, 0.  ],\n",
       "       [1.11, 1.12, 1.08, 1.09, 0.  ],\n",
       "       [1.1 , 1.17, 1.09, 1.13, 0.  ],\n",
       "       [1.12, 1.15, 1.11, 1.13, 0.  ],\n",
       "       [1.12, 1.15, 1.09, 1.1 , 0.  ],\n",
       "       [1.1 , 1.11, 1.06, 1.06, 0.  ],\n",
       "       [1.06, 1.11, 1.05, 1.09, 0.  ]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gather the EURO to Dollar Historical Exchange Rate File and pull the data. We will use it for exchange rates function.\n",
    "file_location_2= \"EUR-USD.csv\"\n",
    "EUR_USD= np.genfromtxt(file_location_2, delimiter= \",\", autostrip= True)\n",
    "EUR_USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Open', 'High', 'Low', 'Close', 'Volume'],\n",
       "       ['1.2098628282546997', '1.2098628282546997', '1.11055588722229', '1.1287955045700073', '0'],\n",
       "       ['1.1287955045700073', '1.1484194993972778', '1.117680549621582', '1.1205360889434814',\n",
       "        '0'],\n",
       "       ['1.119795799255371', '1.1240400075912476', '1.0460032224655151', '1.0830246210098267',\n",
       "        '0'],\n",
       "       ['1.0741022825241089', '1.1247594356536865', '1.0521597862243652', '1.1114321947097778',\n",
       "        '0'],\n",
       "       ['1.1215037107467651', '1.145304799079895', '1.0821995735168457', '1.0960345268249512',\n",
       "        '0'],\n",
       "       ['1.095902442932129', '1.1428401470184326', '1.0888904333114624', '1.122296690940857', '0'],\n",
       "       ['1.1134989261627197', '1.1219995021820068', '1.081270456314087', '1.0939244031906128',\n",
       "        '0'],\n",
       "       ['1.0969001054763794', '1.1705996990203857', '1.0850305557250977', '1.1340054273605347',\n",
       "        '0'],\n",
       "       ['1.1225990056991577', '1.1460003852844238', '1.1089695692062378', '1.1255937814712524',\n",
       "        '0'],\n",
       "       ['1.1171561479568481', '1.1494200229644775', '1.0910003185272217', '1.100897192955017',\n",
       "        '0'],\n",
       "       ['1.1024993658065796', '1.1060001850128174', '1.056400179862976', '1.0583018064498901',\n",
       "        '0'],\n",
       "       ['1.0572947263717651', '1.107000470161438', '1.0541995763778687', '1.093398094177246', '0']],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change dtype to strings to check the column names \n",
    "EUR_USD= np.genfromtxt(file_location_2, delimiter= \",\", autostrip= True, dtype= np.str_)\n",
    "EUR_USD #Okay now we see the columns as Open, High, Low, Close & Volume. Data about stock prices & exchange rates.\n",
    "#Open: Exchange rate at beginning of day, High: Highest value of the day, Low: Lowest value of the day,\n",
    "#Close: Exchange rate at end of day,ie, Adjusted closing prices, Volume: The number of trades made on that day\n",
    "#However, volume is 0, as exchange rate doesn't buy/sell itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13, 1.12, 1.08, 1.11, 1.1 , 1.12, 1.09, 1.13, 1.13, 1.1 , 1.06, 1.09])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only get the 'Close' column from the file for analytics..\n",
    "#As we only care about the adjusted closing prices for our analytics here, we only need to use that.\n",
    "EUR_USD= np.genfromtxt(file_location_2, delimiter= \",\", autostrip= True, \n",
    "                       skip_header= 1, usecols= 3)\n",
    "EUR_USD #We only require exchange rates at the close of the day for our analytics. Hence, high, low, open & volume can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  0,  9, ...,  6,  4, 12])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check all the issue dates from Loan Data Strings dataset\n",
    "loan_data_strings[:,0] #The value represents which month it was issued. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1 , 1.11, 1.13, ..., 1.12, 1.11, 1.09])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we are not using a fixed exchange rate, we have to make adjustments and store it for each account.\n",
    "exchange_rate= loan_data_strings[:,0] #Because it contains all the application issue dates\n",
    "\n",
    "for i in range(1,13): #Goes through 1 - 12 months \n",
    "    exchange_rate = np.where(exchange_rate == i,\n",
    "                             EUR_USD[i-1], #Substitute for average exchange rate. i-1 is used here, \n",
    "                             exchange_rate) #as index in starts from 0: Jan.\n",
    "\n",
    "#For accounts with no issue dates: Assign the annual exchange rate for 2015 (reasonable assumption)\n",
    "exchange_rate = np.where(exchange_rate == 0,\n",
    "                         np.mean(EUR_USD),\n",
    "                         exchange_rate)\n",
    "\n",
    "#Now display the new variable\n",
    "exchange_rate #Contains the associated exchange rate for every element of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.06, 1.08, 1.09, 1.09, 1.1 , 1.1 , 1.11, 1.11, 1.12, 1.12, 1.13, 1.13, 1.13])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check all the unique values of the dataset\n",
    "np.unique(exchange_rate) #Minimum: 0, Maximum: 1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the shape attributes are comparable\n",
    "exchange_rate.shape #1-D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the shape attributes are comparable\n",
    "loan_data_numeric.shape #2-D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to rehape exchange rate so that we can add the data to the loan data numeric dataset\n",
    "exchange_rate= np.reshape(exchange_rate, (10000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now use hstack function to add the exchange rate data to loan data numeric dataset\n",
    "loan_data_numeric= np.hstack((loan_data_numeric, exchange_rate)) #Save it in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  , ...,     1184.86,     9452.96,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    30000.  , ...,      938.57,     4679.7 ,        1.11],\n",
       "       [59432726.  ,    15000.  ,    15000.  , ...,      494.86,     1969.83,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , ...,     1372.97,     2185.64,        1.12],\n",
       "       [46154151.  ,    35000.  ,    10000.  , ...,      354.3 ,     3199.4 ,        1.11],\n",
       "       [66055249.  ,    10000.  ,    10000.  , ...,      309.97,      301.9 ,        1.09]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the newly amended dataset\n",
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Also, change the header numeric function as a new column has been added\\nheader_numeric= np.concatenate((header_numeric, 'exchange_rate')) #1-D vectore & 0-D scalar. Hence, error.\\nheader_numeric #ValueError: all the input arrays must have same number of dimensions, \\n#but the array at index 0 has 1 dimension(s) and the array at index 1 has 0 dimension(s)\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Also, change the header numeric function as a new column has been added\n",
    "header_numeric= np.concatenate((header_numeric, 'exchange_rate')) #1-D vectore & 0-D scalar. Hence, error.\n",
    "header_numeric #ValueError: all the input arrays must have same number of dimensions, \n",
    "#but the array at index 0 has 1 dimension(s) and the array at index 1 has 0 dimension(s)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Also, change the header numeric function as a new column has been added\n",
    "header_numeric= np.concatenate((header_numeric, np.array(['exchange_rate']))) \n",
    "header_numeric #Converted 0-D scalar to array to solve the error. Success!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Currency Change***\n",
    "##### ***From USD to EUR***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Have another look at the header to verify\n",
    "header_numeric #We can see 4 columns, loan & funded amount, installment & total payment,\n",
    "#to be in dollars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid repetitive code for currency conversion, we use a new variable\n",
    "columns_dollar= np.array([1,2,4,5]) #All the columns using dollars by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[35000.  , 35000.  ,  1184.86,  9452.96]],\n",
       "\n",
       "       [[30000.  , 30000.  ,   938.57,  4679.7 ]],\n",
       "\n",
       "       [[15000.  , 15000.  ,   494.86,  1969.83]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[10000.  , 10000.  ,  1372.97,  2185.64]],\n",
       "\n",
       "       [[35000.  , 10000.  ,   354.3 ,  3199.4 ]],\n",
       "\n",
       "       [[10000.  , 10000.  ,   309.97,   301.9 ]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now display only the dollar columns in a 2-D array.\n",
    "loan_data_numeric[:,[columns_dollar]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1 , 1.11, 1.13, ..., 1.12, 1.11, 1.09])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now display the exchange rate column only\n",
    "loan_data_numeric[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the euro version of the data to the dollar counterpart\n",
    "#To do that we will run a loop replacing the dollar data and stack it horizontally \n",
    "for i in columns_dollar:\n",
    "    loan_data_numeric = np.hstack((loan_data_numeric, \n",
    "                                   np.reshape(loan_data_numeric[:,i] / loan_data_numeric[:,6], \n",
    "                                              (10000,1))))\n",
    "\n",
    "#The loan data numeric equals the horizontal stacking hstack. The first input will be the entire datasaet loan_data_numeric,\n",
    "#because we want the existing dataset. Then we'll reference a column depending on the iterator variable i, and then divide it by the exchange rate (stored in 7th column of the numeric dataset).\n",
    "#We need to divide by exchange rate as it shows how much the euro is worth in dollars, rather than multiply it to get the corresponding numbers in euros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  , ...,    31933.3 ,     1081.04,     8624.69],\n",
       "       [57693261.  ,    30000.  ,    30000.  , ...,    27132.46,      848.86,     4232.39],\n",
       "       [59432726.  ,    15000.  ,    15000.  , ...,    13326.3 ,      439.64,     1750.04],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , ...,     8910.3 ,     1223.36,     1947.47],\n",
       "       [46154151.  ,    35000.  ,    10000.  , ...,     8997.4 ,      318.78,     2878.63],\n",
       "       [66055249.  ,    10000.  ,    10000.  , ...,     9145.8 ,      283.49,      276.11]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the new dataset\n",
    "loan_data_numeric #Had to use loan_data_numeric[:, i] / 1.10 to ensure data integrity instead,\n",
    "#of having values divided by 0 & skewing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the new dataset shape\n",
    "loan_data_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Expanding the Header***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also need to update the header as new columns were added to the dataset\n",
    "header_additional= np.array([column_name + '_EUR' \n",
    "                             for column_name \n",
    "                             in header_numeric[columns_dollar]]) \n",
    "#Goes through the dollar columns and attaching _EUR after each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'], dtype='<U15')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the additional header \n",
    "header_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate',\n",
       "       'loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'], dtype='<U19')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add this new header to the old header numeric \n",
    "header_numeric= np.concatenate((header_numeric, header_additional))\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good practise to also change the dollar header columns to USD\n",
    "header_numeric[columns_dollar]= np.array([column_name + '_USD' \n",
    "                                          for column_name \n",
    "                                          in header_numeric[columns_dollar]]) \n",
    "#Goes through the dollar columns and attaching _USD after each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'funded_amnt_USD', 'int_rate', 'installment_USD', 'total_pymnt_USD',\n",
       "       'exchange_rate', 'loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the updated numeric header data\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now create a list and we rearrange the columns so that the corresponding USD & EUR columns are adjacent for data clarity\n",
    "columns_index_order= [0,1,7,2,8,3,4,9,5,10,6] #USD-EUR side-by-side for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now call numeric header and rearrange index using the above list\n",
    "header_numeric= header_numeric[columns_index_order] #Columns rearranged neatly for data clarity\n",
    "header_numeric #The dollar columns precede their euro equivalents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  , ...,    31933.3 ,     1081.04,     8624.69],\n",
       "       [57693261.  ,    30000.  ,    30000.  , ...,    27132.46,      848.86,     4232.39],\n",
       "       [59432726.  ,    15000.  ,    15000.  , ...,    13326.3 ,      439.64,     1750.04],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , ...,     8910.3 ,     1223.36,     1947.47],\n",
       "       [46154151.  ,    35000.  ,    10000.  , ...,     8997.4 ,      318.78,     2878.63],\n",
       "       [66055249.  ,    10000.  ,    10000.  , ...,     9145.8 ,      283.49,      276.11]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call numeric loan dataset to check its data\n",
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,     8624.69,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,     4232.39,        1.11],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,     1750.04,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,     1947.47,        1.12],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,     2878.63,        1.11],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,      276.11,        1.09]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arrange the numeric dataset according to the new index order\n",
    "loan_data_numeric= loan_data_numeric[:,columns_index_order]\n",
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tips:**\n",
    "* We appropriately filled out any missing values\n",
    "* Added exchange rates for each applicants (account)\n",
    "* Created EUR versions of the 4 monetary values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Interest Rate***\n",
    "* Assumption: Doesn't change according to currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Disaply the numeric header\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.33, 28.99, 28.99, ..., 28.99, 16.55, 28.99])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the numeric loan dataset \n",
    "loan_data_numeric[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.  , 13.18, 13.33, 13.44, 13.66, 13.67, 13.99, 14.31, 14.33, 14.48, 14.65, 14.85, 14.99,\n",
       "       15.41, 15.59, 15.61, 15.77, 15.99, 16.49, 16.55, 16.59, 16.99, 17.14, 17.27, 17.57, 17.86,\n",
       "       17.97, 18.25, 18.49, 18.54, 18.55, 18.84, 18.99, 19.19, 19.24, 19.48, 19.52, 19.89, 19.99,\n",
       "       20.49, 20.99, 21.67, 21.99, 22.99, 23.99, 24.24, 24.99, 25.57, 25.78, 25.83, 25.89, 25.99,\n",
       "       26.77, 26.99, 27.31, 27.49, 27.88, 28.49, 28.99])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the columns unique values\n",
    "np.unique(loan_data_numeric[:,5]) #Min Interest: 6.00%, Maximum Interest: 28.99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13, 0.29, 0.29, ..., 0.29, 0.17, 0.29])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform the interest rate column to float value instead of percentages\n",
    "loan_data_numeric[:,5]= loan_data_numeric[:,5]/100 #Now all values converted to float\n",
    "loan_data_numeric[:,5] #Success! Now this will make analytics easier! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checkpoint 2: Numeric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the checkpoint function now for the numeric dataset\n",
    "checkpoint2=\"Checkpoint-Numeric\" #Output in same folder\n",
    "checkpoint_numeric= checkpoint(checkpoint2, header_numeric, loan_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "        'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "       dtype='<U19'),\n",
       " array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,     8624.69,        1.1 ],\n",
       "        [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,     4232.39,        1.11],\n",
       "        [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,     1750.04,        1.13],\n",
       "        ...,\n",
       "        [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,     1947.47,        1.12],\n",
       "        [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,     2878.63,        1.11],\n",
       "        [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,      276.11,        1.09]]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now call the checkpoint variable to verify\n",
    "checkpoint_numeric['header'], checkpoint_numeric['data'] #It is successful! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating the \"Complete\" Dataset**\n",
    "* The story so far: The original array was split up into semi-array each with string and numeric parts divided.\n",
    "* Both the array were cleaned and pre-processed separately.\n",
    "* Now we can finalize the dataset by combining the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The two arrays must have compatible shapes to be joined together\n",
    "#loan_data_numeric.shape - This is also correct\n",
    "#loan_data_strings.shape - This is also correct\n",
    "\n",
    "#However, we must use checkpoints to compare as the arrays might be altered from original\n",
    "checkpoint_strings['data'].shape #10000 x 6 - 2-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use checkpoints to compare as the arrays might be altered from original\n",
    "checkpoint_numeric['data'].shape #10000 x 11 - 2-D array\n",
    "#Yes, both arrays can be stacked as they have same number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,       13.  ,        1.  ,        1.  ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,        5.  ,        1.  ,        4.  ],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,       10.  ,        1.  ,        4.  ],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,        5.  ,        1.  ,        1.  ],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,       17.  ,        1.  ,        3.  ],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,        4.  ,        0.  ,        3.  ]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The arrays can be stacked as they have same number of rows\n",
    "#The numerical dataset will be called first as it has the ID column in it.\n",
    "np.hstack((checkpoint_numeric['data'], checkpoint_strings['data'])) #Fantastic! It worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 17)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check shape to see if it worked correctly. Yes, 11 + 6 columns = 17 columns.\n",
    "np.hstack((checkpoint_numeric['data'], checkpoint_strings['data'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now store the stacked data in a new completed loan dataset\n",
    "loan_data= np.hstack((checkpoint_numeric['data'], checkpoint_strings['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,       13.  ,        1.  ,        1.  ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,        5.  ,        1.  ,        4.  ],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,       10.  ,        1.  ,        4.  ],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,        5.  ,        1.  ,        1.  ],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,       17.  ,        1.  ,        3.  ],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,        4.  ,        0.  ,        3.  ]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now to check if it contains the stacked array\n",
    "loan_data #Wonderful! It worked!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determine how many missing values are still left in the array. It should be 0 as the datasets were cleaned beforehand.\n",
    "np.isnan(loan_data).sum() #Yes! It worked as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate',\n",
       "       'issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now to combine the header arrays of the numeric and string header and complete it in header_full array.\n",
    "header_full= np.concatenate((checkpoint_numeric['header'], checkpoint_strings['header']))\n",
    "#As numeric loan dataset was stiched first, the numeric should also be first argument \n",
    "header_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Sorting the New Dataset***\n",
    "* We want to rearrange the entire dataset according to the values of the first column, ie, ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the value of the first column\n",
    "loan_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  373332.,   575239.,   707689., ..., 68614880., 68615915., 68616519.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now sort the value of the first column only to check\n",
    "np.sort(loan_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2086, 4812, 2353, ..., 4935, 9388, 8415], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now sort the indices of the first column\n",
    "np.argsort(loan_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now pass the dataset index with the argsort function and store the values\n",
    "loan_data= loan_data[np.argsort(loan_data[:,0])] #Passed the first column as sorted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     9950.  ,     9038.08, ...,       21.  ,        0.  ,        1.  ],\n",
       "       [  575239.  ,    12000.  ,    10900.2 , ...,       25.  ,        1.  ,        2.  ],\n",
       "       [  707689.  ,    10000.  ,     8924.3 , ...,       13.  ,        1.  ,        0.  ],\n",
       "       ...,\n",
       "       [68614880.  ,     5600.  ,     5121.65, ...,        8.  ,        1.  ,        1.  ],\n",
       "       [68615915.  ,     4000.  ,     3658.32, ...,       10.  ,        1.  ,        2.  ],\n",
       "       [68616519.  ,    21600.  ,    19754.93, ...,        3.  ,        0.  ,        2.  ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the sorted dataset\n",
    "loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now call argsort function on the first column again to check\n",
    "np.argsort(loan_data[:,0]) #Yes, Verified!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Storing the New Dataset***\n",
    "* Now we can stack the header dataset alongwith the combined loan dataset to complete it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'loan_amnt_USD', 'loan_amnt_EUR', ..., 'sub_grade', 'verification_status',\n",
       "        'state_address'],\n",
       "       ['373332.0', '9950.0', '9038.082814338286', ..., '21.0', '0.0', '1.0'],\n",
       "       ['575239.0', '12000.0', '10900.20037910145', ..., '25.0', '1.0', '2.0'],\n",
       "       ...,\n",
       "       ['68614880.0', '5600.0', '5121.647851612413', ..., '8.0', '1.0', '1.0'],\n",
       "       ['68615915.0', '4000.0', '3658.319894008867', ..., '10.0', '1.0', '2.0'],\n",
       "       ['68616519.0', '21600.0', '19754.927427647883', ..., '3.0', '0.0', '2.0']], dtype='<U32')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stack the header vertically with the dataset. dtype converted to Unicode-32.\n",
    "np.vstack((header_full, loan_data)) #Header argument first to ensure, header stays on top\n",
    "#We see that the stack converted all the data to text again.\n",
    "#This is because the stack requires a unified datatype across all rows & columns\n",
    "#By default, the function selects the smallest datatype that can hold any of the elements within the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'loan_amnt_USD', 'loan_amnt_EUR', ..., 'sub_grade', 'verification_status',\n",
       "        'state_address'],\n",
       "       ['373332.0', '9950.0', '9038.082814338286', ..., '21.0', '0.0', '1.0'],\n",
       "       ['575239.0', '12000.0', '10900.20037910145', ..., '25.0', '1.0', '2.0'],\n",
       "       ...,\n",
       "       ['68614880.0', '5600.0', '5121.647851612413', ..., '8.0', '1.0', '1.0'],\n",
       "       ['68615915.0', '4000.0', '3658.319894008867', ..., '10.0', '1.0', '2.0'],\n",
       "       ['68616519.0', '21600.0', '19754.927427647883', ..., '3.0', '0.0', '2.0']], dtype='<U32')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now store the values in the combined array dataset\n",
    "loan_data= np.vstack((header_full, loan_data)) \n",
    "loan_data #It worked!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now sav the Pre-Processed data in a proper filename\n",
    "np.savetxt('loan-data-preprocessed.csv',\n",
    "           loan_data,\n",
    "           fmt= '%s',\n",
    "           delimiter= ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****ADDENDUM:****\n",
    "* Successfully cleaned the dataset\n",
    "* Then pre-processed the dataset\n",
    "* Finally, prepared the dataset for further analysis\n",
    "\n",
    "* The Data Science team can now take this dataset and create a 'Credit Risk Model' for estimating the probability of default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **THE END**       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
